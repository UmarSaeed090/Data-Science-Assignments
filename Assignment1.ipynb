{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKVrWQt_7agS"
      },
      "source": [
        "Question No 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8lj4c3432Dfz"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "url = \"https://www.imdb.com/chart/top/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SPICmP-j3hC-"
      },
      "outputs": [],
      "source": [
        "def scrape_imdb_top_250(url):\n",
        "\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    movie_items = soup.find_all('td', class_='titleColumn')\n",
        "\n",
        "    data = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK13y9aU3nVC"
      },
      "outputs": [],
      "source": [
        " for movie in movie_items:\n",
        "        \n",
        "        title = movie.a.text\n",
        "        year = movie.span.text.strip('()')\n",
        "        rating = movie.parent.find('td', class_='ratingColumn imdbRating').text.strip()\n",
        "        duration = movie.parent.find('span', class_='runtime').text.strip()\n",
        "\n",
        "        \n",
        "        data.append([title, year, duration, rating])\n",
        "\n",
        " return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIFYYvl_4P-d"
      },
      "outputs": [],
      "source": [
        "\n",
        "movies_data = scrape_imdb_top_250(url)\n",
        "csv_file_path = \"imdb_top_250.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsKpXhns3qwk"
      },
      "outputs": [],
      "source": [
        "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
        "\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow([\"Title\", \"Year\", \"Duration\", \"IMDb Rating\"])\n",
        "    writer.writerows(movies_data)\n",
        "\n",
        "print(\"Data has been successfully exported to:\", csv_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk5HbM_z9AIn"
      },
      "source": [
        "Question No 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oW8utwqt9G0u"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "url = \"https://space-facts.com/mars/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhwmXHur-bC6"
      },
      "outputs": [],
      "source": [
        "def scrape_mars_profile(url):\n",
        "\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    table = soup.find('table', class_='tablepress tablepress-id-p-mars')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbZ0bDdM-fDx"
      },
      "outputs": [],
      "source": [
        "if table:\n",
        "\n",
        "        with open(\"mars_profile_data.xlsx\", 'w', newline='', encoding='utf-8') as f:\n",
        "            writer = csv.writer(f)\n",
        "            for row in table.find_all('tr'):\n",
        "                columns = row.find_all('td')\n",
        "                if len(columns) == 2:\n",
        "                    key = columns[0].text.strip()\n",
        "                    value = columns[1].text.strip()\n",
        "                    writer.writerow([key, value])\n",
        "        print(\"Data has been successfully exported to: mars_profile_data.xlsx\")\n",
        "else:\n",
        "        print(\"Table not found on the webpage.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7PYNRur-tAM",
        "outputId": "e2d183ca-dda4-4f67-ef52-f6c3000662de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data has been successfully exported to: mars_profile_data.xlsx\n"
          ]
        }
      ],
      "source": [
        "     mars_profile_data = scrape_mars_profile(url)\n",
        "\n",
        "df = pd.DataFrame(mars_profile_data, columns=['Attribute', 'Value'])\n",
        "\n",
        "excel_file_path = \"mars_profile_data.xlsx\"\n",
        "df.to_excel(excel_file_path, index=False)\n",
        "\n",
        "print(\"Data has been successfully exported to:\", excel_file_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
